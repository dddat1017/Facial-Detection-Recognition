{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "BASE_DIR = os.getcwd()    # get the path location of this python file (or the path location to this notebook).\n",
    "image_dir = os.path.join(BASE_DIR, \"images\")    # get path location of 'images' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intel built-in haar cascade classifiers. Use for detection.\n",
    "face_cascade = cv2.CascadeClassifier(\"cascades/data/haarcascade_frontalface_alt2.xml\")    # front-of-face cascade.\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()    # creating an LBPH Face Recognizer from CV2.\n",
    "\n",
    "x_train = []    # initializing an empty list for the NUMPY arrays (i.e. pixel values) that correspond to the specific\n",
    "# faces within the images.\n",
    "y_labels = []    # initializing an empty list for image label ID's.\n",
    "current_id = 0    # initializing label ID's to 0.\n",
    "labels_ids = {}    # initializing empty dictionary for label-ID (KEY=label, VALUE=ID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through EACH image folder within 'images'. Get path of each image & label (name of person in image as well as\n",
    "# name of the folder that image is located in) + MORE.\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    # Go through EACH image.\n",
    "    for file in files:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\") or file.endswith(\"jpeg\"):\n",
    "            img_path = os.path.join(root, file)    # get path location of image.\n",
    "            img_label = os.path.basename(root).upper()    # get label of image i.e. name of person the image is showing.\n",
    "            print(img_label, img_path)\n",
    "\n",
    "            # If the label of the image is not already in the dictionary (which all won't be to begin with), then assign\n",
    "            # the value of the 'current_id' to that label in the dictionary. Then, current_id++.\n",
    "            if img_label not in labels_ids:\n",
    "                labels_ids[img_label] = current_id\n",
    "                current_id += 1\n",
    "            id_ = labels_ids[img_label]    # 'id_' is the value associating to a certain label in the dictionary.\n",
    "\n",
    "            pil_image = Image.open(img_path).convert(\"L\")    # returns the image corresponding to the path in grayscale.\n",
    "            size = (300, 300)    # resize all images to this dimension.\n",
    "            final_img = pil_image.resize(size, Image.ANTIALIAS)\n",
    "            img_array = np.array(final_img, \"uint8\")    # turns the image into NUMPY array.\n",
    "\n",
    "            # Face detection from image array.\n",
    "            faces = face_cascade.detectMultiScale(img_array, scaleFactor=1.3, minNeighbors=5)\n",
    "            for (x, y, w, h) in faces:\n",
    "                roi = img_array[y:y+h, x:x+w]\n",
    "                x_train.append(roi)    # add to the 'x_train' list the ROI (face), but in a NUMPY array.\n",
    "                y_labels.append(id_)    # add to the 'y_labels' list the ID's associating to each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pickle to save the label-ID dictionary in order to use in the Model.\n",
    "with open(\"labels.pickle\", \"wb\") as f:\n",
    "    pickle.dump(labels_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the recognizer with the training data (NUMPY arrays of the ROI's) and the labels (in a NUMPY array).\n",
    "recognizer.train(x_train, np.array(y_labels))\n",
    "recognizer.save(\"training_data.yml\")    # saving the trained data file as .yml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
