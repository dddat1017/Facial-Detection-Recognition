{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages\n",
    "1. __OpenCV__ - *Open Source Computer Vision Library, is an open source computer vision and machine learning software library ... The library has more than 2500 optimized algorithms ... These algorithms can be used to detect and recognize faces, identify objects, classify human actions in videos, track camera movements, track moving objects, etc.* - opencv.org\n",
    "2. __Numpy__ - *NumPy, is the fundamental package for scientific computing with Python ... NumPy can also be used as an efficient multi-dimensional container of generic data.* - numpy.org\n",
    "3. __OS__ - *OS, is a built-in module from Python. The functions OS provides, allows for interfacing with the underlying operating system Python is running on (e.g. Mac, Windows, Linux).*\n",
    "4. __PIL & Image__ - *Python Imaging Library (PIL) adds support for opening, manipulating, and saving many different image file formats. Image is a Module within the Library.*\n",
    "5. __Pickle__ - *Pickle converts Python objects (object from a class, variable, list, etc.) to byte stream and then back again. With Machine Learning, saving Classifier.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "BASE_DIR = os.getcwd()    # get the path location of this python file (or the path location to this notebook).\n",
    "image_dir = os.path.join(BASE_DIR, \"images\")    # get path location of 'images' file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Binary Patterns Histograms (LBPH) Face Recognizer\n",
    "\n",
    "![title](Notebook_Materials/LBP_Binary.png)\n",
    "__LBP conversion to binary__. *Source: LoÃÅpez & Ruiz; Local Binary Patterns applied to Face Detection and Recognition.* \n",
    "\n",
    "![title](Notebook_Materials/Sample_Histogram.png)\n",
    "__Sample Histogram__. *Source: superdatascience.com/opencv-face-recognition*\n",
    "\n",
    "![title](Notebook_Materials/Principal_Components.png)\n",
    "__LBPH Face Recognizer Principal Components__. *Source: docs.opencv.org*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV has pre-trained classifier for detecting objects. In this case, faces (frontal).\n",
    "face_cascade = cv2.CascadeClassifier(\"cascades/data/haarcascade_frontalface_alt2.xml\")    # load the XML face \n",
    "# (frontal) classifier.\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()    # creating an LBPH (Local Binary Patterns Histograms) Face\n",
    "# Recognizer from OpenCV.\n",
    "\n",
    "x_train = []    # initializing an empty list for the NUMPY arrays (i.e. pixel values) that correspond to the specific\n",
    "# faces within the images.\n",
    "y_labels = []    # initializing an empty list for image label ID's.\n",
    "current_id = 0    # initializing label ID's to 0.\n",
    "labels_ids = {}    # initializing empty dictionary for label-ID (KEY=label, VALUE=ID)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "\n",
    "## Looping\n",
    "    Loop through the folders in 'images'.\n",
    "        Loop through each folder found in 'images'.\n",
    "            If a file (image) ends with *png*, *jpg*, or *jpeg*, then execute the body of code.\n",
    "\n",
    "### Each iteration\n",
    "    1. Get path location of image/ label of image.\n",
    "    2. Assign an ID to the image.\n",
    "    3. Append to a dictionary the ID that corresponds to a specific Label (name).\n",
    "    4. Convert image to grayscale & resize to (300, 300).\n",
    "    5. Turn image into NUMPY array.\n",
    "    6. Face Detection Loop.\n",
    "        A. Detect ROI (face) within the image.\n",
    "        B. Append the NUMPY array of the ROI to 'x_train'.\n",
    "        C. Append the corresponding ID of the image to 'y_labels'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through EACH image folder within 'images'. Get path of each image & label (name of person in image as well as\n",
    "# name of the folder that image is located in) + MORE.\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    # Go through EACH image.\n",
    "    for file in files:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\") or file.endswith(\"jpeg\"):\n",
    "            img_path = os.path.join(root, file)    # get path location of image.\n",
    "            img_label = os.path.basename(root).upper()    # get label of image i.e. name of person the image is showing.\n",
    "\n",
    "            # If the label of the image is not already in the dictionary (which all won't be to begin with), then assign\n",
    "            # the value of the 'current_id' to that label in the dictionary. Then, current_id++.\n",
    "            if img_label not in labels_ids:\n",
    "                labels_ids[img_label] = current_id\n",
    "                current_id += 1\n",
    "            id_ = labels_ids[img_label]    # 'id_' is the value associating to a certain label in the dictionary.\n",
    "            \n",
    "            print(id_, img_label, img_path)\n",
    "\n",
    "            pil_image = Image.open(img_path).convert(\"L\")    # returns the image corresponding to the path in grayscale.\n",
    "            size = (300, 300)    # resize all images to this dimension.\n",
    "            final_img = pil_image.resize(size, Image.ANTIALIAS)\n",
    "            img_array = np.array(final_img, \"uint8\")    # turns the image into NUMPY array.\n",
    "\n",
    "            # Face detection from image array.\n",
    "            faces = face_cascade.detectMultiScale(img_array, scaleFactor=1.3, minNeighbors=5)\n",
    "            for (x, y, w, h) in faces:\n",
    "                roi = img_array[y:y+h, x:x+w]\n",
    "                x_train.append(roi)    # add to the 'x_train' list the ROI (face), but in a NUMPY array.\n",
    "                y_labels.append(id_)    # add to the 'y_labels' list the ID's associating to each label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Labels & ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pickle to save the label-ID dictionary in order to use in the Model.\n",
    "with open(\"labels_ids.pickle\", \"wb\") as f:\n",
    "    pickle.dump(labels_ids, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the recognizer with the training data (NUMPY arrays of the ROI's) and the ID's (in a NUMPY array).\n",
    "recognizer.train(x_train, np.array(y_labels))\n",
    "recognizer.save(\"training_data.yml\")    # saving the trained data file as .yml."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
